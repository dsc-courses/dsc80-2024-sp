{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a44b8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from dsc80_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2b2f7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# The dataset is built into plotly (and seaborn)!\n",
    "# We shuffle here so that the head of the DataFrame contains rows where smoker is Yes and smoker is No,\n",
    "# purely for illustration purposes (it doesn't change any of the math).\n",
    "np.random.seed(1)\n",
    "tips = px.data.tips().sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca51859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 14 ‚Äì Feature Engineering\n",
    "\n",
    "## DSC 80, Spring 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22824200",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements üì£\n",
    "\n",
    "- Lab 7 is due **tomorrow**.\n",
    "- The Final Project is out!\n",
    "    - It will be worth two projects (because it used to be two separate projects). \n",
    "    - It will have two short checkpoints due this Friday and next Friday.\n",
    "    - You **can** request an extension on the checkpoints.\n",
    "    - You **cannot** request an extension on final submission deadline on **Wednesday, June 12** (the Wed of finals week)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd851d5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda üìÜ\n",
    "\n",
    "- Review: Predicting tips.\n",
    "    - $R^2$.\n",
    "- Feature engineering.\n",
    "    - Example: Predicting tips.\n",
    "        - One hot encoding.\n",
    "    - Example: Predicting ratings ‚≠êÔ∏è.\n",
    "        - Dropping features.\n",
    "        - Ordinal encoding.\n",
    "    - Example: Horsepower üöó.\n",
    "        - Quantitative scaling.\n",
    "- Feature engineering in `sklearn`.\n",
    "    - Transformer classes.\n",
    "    - Creating `Pipeline`s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce21ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Review: Predicting tips üßë‚Äçüç≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3cdc9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fbdebf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear models\n",
    "\n",
    "Last time, we _fit_ three linear models to predict restaurant tips:\n",
    "\n",
    "- Constant model: $\\text{predicted tip} = h$.\n",
    "- Simple linear regression: $\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill}$.\n",
    "- Multiple linear regression: $\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648de16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the constant model case, we know that the optimal model parameter, when using squared loss, is $h^* = \\text{mean tip}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tip = tips['tip'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a60f9e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the other two cases, we used the `LinearRegression` class from `sklearn` to help us find optimal model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X=tips[['total_bill']], y=tips['tip'])\n",
    "\n",
    "model_two = LinearRegression()\n",
    "model_two.fit(X=tips[['total_bill', 'size']], y=tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912e89f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root mean squared error\n",
    "\n",
    "To compare the performance of different models, we used the root mean squared error (RMSE).\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i = 1}^n \\big( y_i - H(x_i) \\big)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca68d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, pred):\n",
    "    return np.sqrt(np.mean((actual - pred) ** 2))\n",
    "\n",
    "rmse_dict = {}\n",
    "rmse_dict['constant tip amount'] = rmse(tips['tip'], mean_tip)\n",
    "\n",
    "all_preds = model.predict(tips[['total_bill']])\n",
    "rmse_dict['one feature: total bill'] = rmse(tips['tip'], all_preds)\n",
    "\n",
    "rmse_dict['two features'] = rmse(\n",
    "    tips['tip'], model_two.predict(tips[['total_bill', 'size']])\n",
    ")\n",
    "\n",
    "pd.DataFrame({'rmse': rmse_dict.values()}, index=rmse_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5807ae07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The `.score` method of a `LinearRegression` object\n",
    "\n",
    "Model objects in `sklearn` that have already been fit have a `score` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5bd253",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That doesn't look like the RMSE... what is it? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17aa8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77394e99",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $R^2$, or the **coefficient of determination**, is a measure of the **quality of a linear fit**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07cdd7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are a few equivalent ways of computing it, assuming your model **is linear and has an intercept term**:\n",
    "\n",
    "$$R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$$\n",
    "\n",
    "$$R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe95d1a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Interpretation: $R^2$ is the **proportion of variance in $y$ that the linear model explains**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fa9fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the simple linear regression case, it is the square of the correlation coefficient, $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a320f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Key idea:** $R^2$ ranges from 0 to 1. **The closer it is to 1, the better the linear fit is.**\n",
    "    - $R^2$ has no units of measurement, unlike RMSE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10277e74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating $R^2$\n",
    "\n",
    "Let's calculate the $R^2$ for `model_two`'s predictions in three different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68507b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = tips.assign(predicted=model_two.predict(tips[['total_bill', 'size']]))\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57861383",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 1: $R^2 = \\frac{\\text{var}(\\text{predicted $y$ values})}{\\text{var}(\\text{actual $y$ values})}$**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(pred['predicted']) / np.var(pred['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a91f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 2:** $R^2 = \\left[ \\text{correlation}(\\text{predicted $y$ values}, \\text{actual $y$ values}) \\right]^2$\n",
    "\n",
    "Note: By correlation here, we are referring to $r$, the same correlation coefficient you saw in DSC 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.corr().loc['predicted', 'tip'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fe309",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Method 3:** `LinearRegression.score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ffe7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_two.score(tips[['total_bill', 'size']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3f084",
   "metadata": {},
   "source": [
    "All three methods provide the same result!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be25a789",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Relationship between $R^2$ and RMSE\n",
    "\n",
    "For linear models with an intercept term,\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\text{RMSE}^2}{\\text{var}(\\text{actual $y$ values})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - rmse(pred['tip'], pred['predicted']) ** 2 / np.var(pred['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe9967",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What's next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153988b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So far, in our journey to predict `'tip'`, we've only used the existing numerical features in our dataset, `'total_bill'` and `'size'`.\n",
    "\n",
    "- There's a lot of information in tips that we didn't use ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'`, for example. We can't use these features in their current form, because they're non-numeric.\n",
    "\n",
    "- **How do we use categorical features in a regression model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b777e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature engineering ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b929487",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The goal of feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7c091",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Feature engineering** is the act of finding **transformations** that transform data into effective **quantitative variables**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4a790",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A feature function $\\phi$ (phi, pronounced \"fea\") is a mapping from raw data to $d$-dimensional space, i.e. $\\phi: \\text{raw data} \\rightarrow \\mathbb{R}^d$.\n",
    "    - If two observations $x_i$ and $x_j$ are \"similar\" in the raw data space, then $\\phi(x_i)$ and $\\phi(x_j)$ should also be \"similar.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a5032",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A \"good\" choice of features depends on many factors:\n",
    "    - The kind of data, i.e. quantitative, ordinal, or nominal.\n",
    "    - The relationship(s) being modeled.\n",
    "    - The model type, e.g. linear models, decision tree models, neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac781d68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To introduce different feature functions, we'll look at several different example datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e155a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d4f970",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One hot encoding is a transformation that turns a categorical feature into several binary features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce40fe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Suppose a column has $N$ unique values, $A_1$, $A_2$, ..., $A_N$. For each unique value $A_i$, we define the following **feature function**:\n",
    "\n",
    "$$\\phi_i(x) = \\left\\{\\begin{array}{ll}1 & {\\rm if\\ } x = A_i \\\\ 0 &  {\\rm if\\ } x\\neq A_i \\\\ \\end{array}\\right. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab65ebda",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Note that 1 means \"yes\" and 0 means \"no\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c38fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One hot encoding is also called \"dummy encoding\", and $\\phi(x)$ may also be referred to as an \"indicator variable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc658794",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: One hot encoding `'smoker'`\n",
    "\n",
    "For each unique value of `'smoker'` in our dataset, we must create a column for just that `'smoker'`. (Remember, `'smoker'` is `'Yes'` when the table was in the smoking section of the restaurant and `'No'` otherwise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips['smoker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c21be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(tips['smoker'] == 'Yes').astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in tips['smoker'].unique():\n",
    "    tips[f'smoker == {val}'] = (tips['smoker'] == val).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44dc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615ccee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model #4: Multiple linear regression using total bill, table size, and smoker status\n",
    "\n",
    "Now that we've converted `'smoker'` to a numerical variable, we can use it as input in a regression model. Here's the model we'll try to fit:\n",
    "\n",
    "$$\\text{predicted tip} = w_0 + w_1 \\cdot \\text{total bill} + w_2 \\cdot \\text{table size} + w_3 \\cdot \\text{smoker == Yes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9911e95",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Subtlety**: There's no need to use _both_ `'smoker == No'` and `'smoker == Yes'`. If we know the value of one, we already know the value of the other. We can use either one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_three = LinearRegression()\n",
    "model_three.fit(tips[['total_bill', 'size', 'smoker == Yes']], tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c29f19",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "The following cell gives us our $w^*$s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08d4ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_three.intercept_, model_three.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00685cb8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Thus, our trained linear model to predict tips given total bills, table sizes, and smoker status (yes or no) is:\n",
    "\n",
    "$$\\text{predicted tip} = 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot \\text{smoker == Yes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a31b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualizing Model #4\n",
    "\n",
    "Our new fit model is:\n",
    "\n",
    "$$\\text{predicted tip} = 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot \\text{smoker == Yes}$$\n",
    "\n",
    "To visualize our data and linear model, we'd need 4 dimensions:\n",
    "- One for total bill\n",
    "- One for table size\n",
    "- One for `'smoker == Yes'`.\n",
    "- One for tip.\n",
    "\n",
    "Humans can't visualize in 4D, but there may be a solution. We know that `'smoker == Yes'` only has two possible values, 1 or 0, so let's look at those cases separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f67d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Case 1**: `'smoker == Yes'` is 1, meaning that the table **was** in the smoking section.\n",
    "\n",
    "$$\\begin{align*} \\text{predicted tip} &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot 1 \\\\ &= 0.626 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size}  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac8dde",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Case 2**: `'smoker == Yes'` is 0, meaning that the table **was not** in the smoking section.\n",
    "\n",
    "$$\\begin{align*} \\text{predicted tip} &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size} - 0.083 \\cdot 0 \\\\ &= 0.709 + 0.094 \\cdot \\text{total bill} + 0.180 \\cdot \\text{table size}  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e760d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Key idea**: These are two parallel planes in 3D, with different $z$-intercepts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3f2ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the two planes are very close to one another ‚Äì you'll have to zoom in to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d205c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.renderers.default = 'plotly_mimetype+notebook' # If it doesn't render, try uncommenting this.\n",
    "\n",
    "XX, YY = np.mgrid[0:50:2, 0:8:1]\n",
    "Z_0 = model_three.intercept_ + model_three.coef_[0] * XX + model_three.coef_[1] * YY + model_three.coef_[2] * 0\n",
    "Z_1 = model_three.intercept_ + model_three.coef_[0] * XX + model_three.coef_[1] * YY + model_three.coef_[2] * 1\n",
    "plane_0 = go.Surface(x=XX, y=YY, z=Z_0, colorscale='Greens')\n",
    "plane_1 = go.Surface(x=XX, y=YY, z=Z_1, colorscale='Purples')\n",
    "\n",
    "fig = go.Figure(data=[plane_0, plane_1])\n",
    "\n",
    "tips_0 = tips[tips['smoker'] == 'No']\n",
    "tips_1 = tips[tips['smoker'] == 'Yes']\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=tips_0['total_bill'], \n",
    "                           y=tips_0['size'], \n",
    "                           z=tips_0['tip'], mode='markers', marker = {'color': 'green'}))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(x=tips_1['total_bill'], \n",
    "                           y=tips_1['size'], \n",
    "                           z=tips_1['tip'], mode='markers', marker = {'color': 'purple'}))\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title='Total Bill',\n",
    "    yaxis_title='Table Size',\n",
    "    zaxis_title='Tip'),\n",
    "  title='Tip vs. Total Bill and Table Size (Green = Non-Smoking Section, Purple = Smoking Section)',\n",
    "    width=1000, height=800,\n",
    "    showlegend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2302b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we want to visualize in 2D, we need to pick a single feature to place on the $x$-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45adfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=tips['tip'], \n",
    "                         mode='markers', name='Original Data'))\n",
    "fig.add_trace(go.Scatter(x=tips['total_bill'], y=model_three.predict(tips[['total_bill', 'size', 'smoker == Yes']]), \n",
    "                         mode='markers', name='Predicted Tips using Total Bill, <br>Table Size, and Smoker Status'))\n",
    "\n",
    "fig.update_layout(showlegend=True, title='Tip vs. Total Bill',\n",
    "                  xaxis_title='Total Bill', yaxis_title='Tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d6c67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Despite being a linear model, why **doesn't** this model **look** like a straight line?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36750de2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparing Model #4 to earlier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bc726",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_dict['three features'] = rmse(tips['tip'], \n",
    "                                   model_three.predict(tips[['total_bill', 'size', 'smoker == Yes']]))\n",
    "rmse_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb6ff2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adding `'smoker == Yes'` decreased the training RMSE of our model, but **barely**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cdc3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2201375c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We've one hot encoded `'smoker'`, but it required a `for`-loop.\n",
    "\n",
    "- Is there an easy way to one hot encode all four categorical columns ‚Äì `'sex'`, `'smoker'`, `'day'`, and `'time'` ‚Äì all at once, without using a `for`-loop?\n",
    "\n",
    "- Yes, using `sklearn.preprocessing`'s `OneHotEncoder`. More on this soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc60709",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "(Fa23 Final Q9.1)\n",
    "   \n",
    "Every week, Lauren goes to her local grocery store and buys a varying amount of vegetable but always buys exactly one pound of meat (either beef, fish, or chicken). We use a linear regression model to predict her total grocery bill. We‚Äôve collected a dataset containing the pounds of vegetables bought, the type of meat bought, and the total bill. Below we display the first few rows of the dataset and two plots generated using the entire training set.\n",
    "    \n",
    "![](imgs/fa23q9.png)\n",
    "\n",
    "Suppose we fit the following linear regression models to predict\n",
    "`total`. Based on the data and visualizations shown above, determine\n",
    "whether the fitted model weights are positive (+), negative (-), or exactly\n",
    "0. The notation `meat=beef` refers to the one-hot encoded `meat`\n",
    "column with value 1 if the original value in the `meat` column was\n",
    "`beef` and 0 otherwise. Likewise, `meat=chicken` and\n",
    "`meat=fish` are the one-hot encoded `meat` columns for\n",
    "`chicken` and `fish`, respectively.\n",
    "    \n",
    "1. $H(x) = w_0 $\n",
    "1. $H(x) = w_0 + w_1 \\cdot \\text{veg} $\n",
    "1. $H(x) = w_0 + w_1 \\cdot (\\text{meat=chicken})  $\n",
    "1. $H(x) = w_0 + w_1 \\cdot (\\text{meat=beef}) + w_2 \\cdot (\\text{meat=chicken}) $\n",
    "1. $H(x) = w_0 + w_1 \\cdot (\\text{meat=beef}) + w_2 \\cdot (\\text{meat=chicken}) + w_3 \\cdot (\\text{meat=fish}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7705f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Predicting ratings ‚≠êÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d7777",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting ratings ‚≠êÔ∏è\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Sick af...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646aaeb4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We want to build a **classifier** that predicts `'RATING'` using the above features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5be580",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why can't we build a model right away? What must we do so that we can build a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d686e2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Some issues: missing values, emojis and strings instead of numbers, irrelevant columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94368ca4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uninformative features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afc37c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `'UID'` was likely used to join the user information (e.g., `'AGE'` and `'STATE'`) with some `reviews` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f18a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Even though `'UID'`s are stored as **numbers**, the numerical value of a user's `'UID'` won't help us predict their `'RATING'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf001f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If we include the `'UID'` feature, our model will find whatever patterns it can between `'UID'`s and `'RATING'`s in the training (observed data).\n",
    "    - This will lead to a lower training RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4ad1e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- However, since there is truly no relationship between `'UID'` and `'RATING'`, this will lead to **worse** model performance on unseen data (bad)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44c96d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropping features\n",
    "\n",
    "There are certain scenarios where manually dropping features might be helpful:\n",
    "\n",
    "1. When the features **do not contain information** associated with the prediction task. \n",
    "2. When the feature is **not available at prediction time.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb7f8b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The goal of building a model to predict `'RATING'`s is so that we can **predict `'RATING'`s for users who haven't actually made a `'RATING'` yet**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ac16bb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, our model should only depend on features that we would know before the user makes their `'RATING'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b286ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For instance, if a user only enters a `'REVIEW'` after entering a `'RATING'`, we shouldn't use their `'REVIEW'` to predict their `'RATING'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea574cfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding ordinal features\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Sick af...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "How do we encode the `'RATING'` column, an ordinal variable, as a quantitative variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c558ee7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Transformation**: Replace \"number of &#10025;\" with \"number\".\n",
    "    - This is an **ordinal encoding**, a transformation that maps ordinal values to the positive integers in a way that preserves order.\n",
    "    - Example: (freshman, sophomore, junior, senior) -> (0, 1, 2, 3).\n",
    "    - **Important**: This transformation preserves \"distances\" between ratings.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e1898",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_enc = {\n",
    "    '‚ú©': 1,\n",
    "    '‚ú©‚ú©': 2,\n",
    "    '‚ú©‚ú©‚ú©': 3,\n",
    "    '‚ú©‚ú©‚ú©‚ú©': 4,\n",
    "    '‚ú©‚ú©‚ú©‚ú©‚ú©': 5,\n",
    "}\n",
    "ordinal_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame().assign(RATING=['‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©', '‚ú©‚ú©‚ú©', '‚ú©', '‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©', '‚ú©‚ú©‚ú©‚ú©‚ú©'])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf292ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.replace(ordinal_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebe95e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Encoding nominal features\n",
    "\n",
    "|UID|AGE|STATE|HAS_BOUGHT|REVIEW|\\||RATING|\n",
    "|---|---|---|---|---|---|---|\n",
    "|74|32|NY|True|\"Meh.\"|\\||&#10025;&#10025;|\n",
    "|42|50|WA|True|\"Worked out of the box...\"|\\||&#10025;&#10025;&#10025;&#10025;|\n",
    "|57|16|CA|NULL|\"Sick af...\"|\\||&#10025;|\n",
    "|...|...|...|...|...|\\||...|\n",
    "|(int)|(int)|(str)|(bool)|(str)|\\||(str)|\n",
    "\n",
    "How do we encode the `'STATE'` column, a nominal variable, as a quantitative variable? In other words, how do we turn `'STATE'`s into meaningful numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d752d5c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Question**: Why can't we use an ordinal encoding, e.g. NY -> 0, WA -> 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966caa51",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Answer**: There is no inherent ordering to states, e.g. WA is not inherently \"more\" of anything than NY."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b211cf3b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **We've already seen the correct strategy**: one hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6cb7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Horsepower üöó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b31c6d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following dataset, built into the `seaborn` plotting library, contains various information about (older) cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74629562",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = sns.load_dataset('mpg').dropna()\n",
    "mpg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b32614",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We really do mean old:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ae514",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg['model_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30a172",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's investigate the relationship between `'horsepower'` and `'mpg'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a3bf75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The relationship between `'horsepower'` and `'mpg'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5268d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.scatter(mpg, x='horsepower', y='mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887d19e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It appears that there is a negative association between `'horsepower'` and `'mpg'`, though it's not quite linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c3860",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Let's try and fit a simple linear model that uses `'horsepower'` to predict `'mpg'` and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc08a100",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `'horsepower'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model = LinearRegression()\n",
    "car_model.fit(mpg[['horsepower']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d9d1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do our predictions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_points = pd.DataFrame({'horsepower': [25, 225]})\n",
    "fig = px.scatter(mpg, x='horsepower', y='mpg')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=hp_points['horsepower'],\n",
    "    y=car_model.predict(hp_points),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using Horsepower'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb17e599",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our regression line doesn't capture the curvature in the relationship between `'horsepower'` and `'mpg'`.\n",
    "\n",
    "Let's look at the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4fc100",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mpg.assign(\n",
    "    Predictions=car_model.predict(mpg[['horsepower']]),\n",
    "    Residuals=mpg['mpg'] - car_model.predict(mpg[['horsepower']]),\n",
    ")\n",
    "fig = px.scatter(res, x='Predictions', y='Residuals')\n",
    "fig.add_hline(0, line_width=3, opacity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model.score(mpg[['horsepower']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff3ec7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linearization\n",
    "\n",
    "The [Tukey Mosteller Bulge Diagram](https://sites.stat.washington.edu/pds/stat423/Documents/LectureNotes/notes.423.ch4.pdf) helps us pick which transformations to apply to data in order to **linearize** it.\n",
    "\n",
    "<center><img src=\"imgs/bulge.png\" width=25%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3164a12",
   "metadata": {},
   "source": [
    "The bottom-left quadrant appears to match the shape of the scatter plot between `'horsepower'` and `'mpg'` the best ‚Äì let's try taking the `log` of `'horsepower'` ($X$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b90482",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg['log hp'] = np.log(mpg['horsepower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b77c02",
   "metadata": {},
   "source": [
    "What does our data look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(mpg, x='log hp', y='mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686dfcd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting `'mpg'` using `log('horsepower')`\n",
    "\n",
    "Let's fit another linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12526744",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log = LinearRegression()\n",
    "car_model_log.fit(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e490f0",
   "metadata": {},
   "source": [
    "What do our predictions look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e44922",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(mpg, x='log hp', y='mpg')\n",
    "log_hp_points = pd.DataFrame({'log hp': [3.7, 5.5]})\n",
    "fig = px.scatter(mpg, x='log hp', y='mpg')\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=log_hp_points['log hp'],\n",
    "    y=car_model_log.predict(log_hp_points),\n",
    "    mode='lines',\n",
    "    name='Predicted MPG using log(Horsepower)'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18fe456",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The fit looks a bit better! How about the $R^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log.score(mpg[['log hp']], mpg['mpg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e1fa5",
   "metadata": {},
   "source": [
    "Also a bit better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a724aa37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What do our predictions look like on the original, non-transformed scatter plot? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(mpg, x='horsepower', y='mpg')\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=mpg['horsepower'], \n",
    "        y=car_model_log.intercept_ + car_model_log.coef_[0] * np.log(mpg['horsepower']),  \n",
    "        mode='markers', name='Predicted MPG using log(Horsepower)'\n",
    "    )\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b93afa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our predictions that used $\\log(\\text{Horsepower})$ as an input don't fall on a straight line. We shouldn't expect them to; the red dots come from:\n",
    "\n",
    "$$\\text{Predicted MPG} = 108.698 - 18.582 \\cdot \\log(\\text{Horsepower})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_model_log.intercept_, car_model_log.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7081a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quantitative scaling\n",
    "\n",
    "Until now, feature transformations we've discussed so far have involved converting **categorical** variables into **quantitative** variables. However, our log transformation was an example of transforming a **quantitative** variable into a new **quantitative** variable; this practice is called quantitative scaling.\n",
    "\n",
    "- **Standardization**: $x_i \\rightarrow \\frac{x_i - \\bar{x}}{\\sigma_x}$.\n",
    "- **Linearization via a non-linear transformation**: e.g. $\\text{log}$ and $\\text{sqrt}$. See Lab 8 for more.\n",
    "- **Discretization**: Convert data into percentiles (or more generally, quantiles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5adde80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScWbVZv9hBv-wX-ItKHUVRnkPMMtfJZVfErKE9GS7_8dFcRBQ/viewform\">q.dsc80.com)</h3>\n",
    "</div>\n",
    "    \n",
    "What questions do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a95ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The modeling process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d14ddab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The modeling process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26e1d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Create, or engineer, features to best reflect the \"meaning\" behind data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e645a03",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. Choose a model that is appropriate to capture the relationships between features ($X$) and the target/response ($y$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92866e92",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. Choose a loss function, e.g. squared loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05939d0e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "4. Fit the model: that is, minimize empirical risk to find optimal model parameters $w^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4b9e78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "5. Evaluate the model, e.g. using RMSE or $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fbedad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**We can perform all of the above directly in `sklearn`!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91d26c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/image_0.png\" width=\"60%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7f04d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `preprocessing` and `linear_model`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc00479",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the **feature engineering** step of the modeling pipeline, we will use `sklearn`'s [`preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module.\n",
    "\n",
    "<center><img src=\"imgs/feature_part.png\" width=\"30%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795bf90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the **model creation** step of the modeling pipeline, we will use `sklearn`'s [`linear_model`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) module, as we've already seen. `linear_model.LinearRegression` is an example of an **estimator** class.\n",
    "\n",
    "<center><img src=\"imgs/model_part.png\" width=\"36%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813b18b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41403a4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Transformer classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b832c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Transformers** take in \"raw\" data and output \"processed\" data. They are used for **creating features**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297cd26",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The input to a transformer should be a multi-dimensional `numpy` array.\n",
    "    - Inputs can be DataFrames, but `sklearn` only looks at the values (i.e. it calls `to_numpy()` on input DataFrames)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc20389",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The output of a transformer is a `numpy` array (never a DataFrame or Series)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f3995",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Transformers, like most relevant features of `sklearn`, are **classes**, not functions, meaning you need to instantiate them and call their methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f64cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Predicting tips üßë‚Äçüç≥\n",
    "\n",
    "We'll continue working with our trusty `tips` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159c00f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `Binarizer`\n",
    "\n",
    "The `Binarizer` transformer allows us to map a quantitative sequence to a sequence of 1s and 0s, depending on whether values are above or below a threshold.\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `binar = Binarizer(thresh)` | set x=1 if x > thresh, else 0|\n",
    "|Transform data in a dataset | `feat = binar.transform(data)` | Binarize all columns in `data`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ec5acd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we need to import the relevant class from `sklearn.preprocessing`. (Tip: import just the relevant classes you need from `sklearn`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95076bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80843c5a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's try binarizing `'total_bill'`. We'll say a \"large\" bill is one that is **strictly** greater than \\$20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f125d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips['total_bill'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8186086",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, we initialize a `Binarizer` object with the threshold we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = Binarizer(threshold=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611bda9c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, we call `bi`'s `transform` method and pass it the data we'd like to transform. Note that its input and output are both 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e13219",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_bills = bi.transform(tips[['total_bill']]) # Must give transform a 2D array/DataFrame.\n",
    "transformed_bills[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc577d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StandardScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b7e11",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- `StandardScaler` **standardizes** data using the mean and standard deviation of the data.\n",
    "\n",
    "$$z(x_i) = \\frac{x_i - \\text{mean of } x}{\\text{SD of } x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf57ce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Unlike `Binarizer`, `StandardScaler` **requires some knowledge (mean and SD) of the dataset before transforming**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2ac75",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As such, we need to **`fit`** an `StandardScaler` transformer before we can use the `transform` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347e31a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Typical usage: fit transformer on a sample, use that fit transformer to transform future data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bbeaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `StandardScaler`\n",
    "\n",
    "It only makes sense to standardize the already-quantitative features of `tips`, so let's select just those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb2ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_quant = tips[['total_bill', 'size']]\n",
    "tips_quant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d684be1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's initialize a `StandardScaler` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03790dc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the following **does not work!** The error message is very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b96342",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "stdscaler.transform(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f6d884",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Instead, we need to first call the `fit` method on `stdscaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2a8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is like saying \"determine the mean and SD of each column in tips_quant\".\n",
    "stdscaler.fit(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f4d3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, `transform` will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d812b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First column is 'total_bill', second column is 'size'.\n",
    "tips_quant_z = stdscaler.transform(tips_quant)\n",
    "tips_quant_z[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fc339",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can also access the mean and variance `stdscaler` computed for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f412d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89daaa5f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that we can call `transform` on DataFrames other than `tips_quant`. We will do this often ‚Äì fit a transformer on one dataset (training data) and use it to transform other datasets (test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.transform(tips_quant.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935239f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### üí° Pro-Tip: Using `.fit_transform`\n",
    "\n",
    "The `.fit_transform` method will fit the transformer and then transform the data in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf51fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.fit_transform(tips_quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6481695",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `StandardScaler` summary\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `stdscaler = StandardScaler()` | z-score the data (no parameters) |\n",
    "|Fit the transformer| `stdscaler.fit(X)` | Compute the mean and SD of `X`|\n",
    "|Transform data in a dataset | `feat = stdscaler.transform(X_new)` | z-score `X_new` with mean and SD of `X`|\n",
    "|Fit and transform| `stdscaler.fit_transform(X)` | Compute the mean and SD of `X`, then z-score `X`|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d017d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example transformer: `OneHotEncoder`\n",
    "\n",
    "Let's keep just the categorical columns in `tips`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f3536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_cat = tips[['sex', 'smoker', 'day', 'time']]\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af220ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Like `StdScaler`, we will need to `fit` our `OneHotEncoder` transformer before it can transform anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f412324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(tips_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373090e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we try and transform, we get a result we might not expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee74801",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(tips_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ae7a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the resulting matrix is **sparse** ‚Äì most of its elements are 0 ‚Äì `sklearn` uses a more efficient representation than a regular `numpy` array. We can convert to a regular (dense) array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aabf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.transform(tips_cat).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6195a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice that the column names from `tips_cat` are no longer stored anywhere (remember, `fit` converts the input to a `numpy` array before proceeding).\n",
    "\n",
    "We can use the `get_feature_names_out` method on `ohe` to access the names of the one-hot-encoded columns, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names_out() # x0, x1, x2, and x3 correspond to column names in tips_cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ohe.transform(tips_cat).toarray(), \n",
    "             columns=ohe.get_feature_names_out()) # If we need a DataFrame back, for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11fd0cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <h3>Question ü§î (Answer at <a class=\"alert-link\" href=\"http://q.dsc80.com\">q.dsc80.com</a>)</h3>\n",
    "</div>\n",
    "    \n",
    "Suppose we have a training set `X_train` with labels `y_train`, and we have a test set `X_test` with labels `y_test`. If we want to use OHE on the `day` column, we will use `ohe.fit_transform(X_train)`, but we will NOT do `ohe.fit_transform(X_test)`. Instead, we will ONLY do `ohe.transform(X_test)`. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833fac9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f71de5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"imgs/image_0.png\" width=\"50%\"></center>\n",
    "\n",
    "<br>\n",
    "\n",
    "So far, we've used transformers for feature engineering and models for prediction. We can combine these steps into a single `Pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd1ef16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `Pipeline`s in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3534d8e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From [`sklearn`'s documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):\n",
    "\n",
    "> Pipeline allows you to sequentially apply a list of transformers to preprocess the data and, **if desired**, conclude the sequence with a final predictor for predictive modeling.<br><br>Intermediate steps of the pipeline must be \"transforms\", that is, they must implement `fit` and `transform` methods. The final estimator only needs to implement `fit`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1553e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- General template: `pl = Pipeline([trans_1, trans_2, ..., model])`\n",
    "    - Note that the `model` is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a409a1d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Once a `Pipeline` is instantiated, you can fit **all** steps (transformers and model) using `pl.fit(X, y)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170591a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To make predictions using **raw, untransformed data**, use `pl.predict(X)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508398a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The actual list we provide `Pipeline` with must be a list of **tuples**, where\n",
    "    - The first element is a \"name\" (that we choose) for the step.\n",
    "    - The second element is a transformer or estimator instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86669e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Our first `Pipeline`\n",
    "\n",
    "Let's build a `Pipeline` that:\n",
    "- One hot encodes the categorical features in `tips`.\n",
    "- Fits a regression model on the one hot encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03859c62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_cat = tips[['sex', 'smoker', 'day', 'time']]\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7cf9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49f763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('one-hot', OneHotEncoder()),\n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56ef92c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that `pl` is instantiated, we `fit` it the same way we would fit the individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03991a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips_cat, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b902c9f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, to make predictions using **raw data**, all we need to do is use `pl.predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict(tips_cat.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8518b9",
   "metadata": {},
   "source": [
    "`pl` performs **both** feature transformation and prediction with just a single call to `predict`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea45098",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can access individual \"steps\" of a `Pipeline` through the `named_steps` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c6298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].transform(tips_cat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f17401",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['lin-reg'].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7b1ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pl` also has a `score` method, the same way a fit `LinearRegression` instance does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is this so low?\n",
    "pl.score(tips_cat, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fc2ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More sophisticated `Pipeline`s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aeac87",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In the previous example, we one hot encoded every input column. **What if we want to perform different transformations on different columns?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3877bd69",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Solution**: Use a `ColumnTransformer`.\n",
    "    - Instantiate a `ColumnTransformer` using a list of tuples, where:\n",
    "        - The first element is a \"name\" we choose for the transformer.\n",
    "        - The second element is a transformer instance (e.g. `OneHotEncoder()`).\n",
    "        - The third element is a **list of relevant column names**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e477c359",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Planning our first `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd28cf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ecc2b",
   "metadata": {},
   "source": [
    "Let's perform different transformations on the quantitative and categorical features of `tips` (note that we are not transforming `'tip'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_features = tips.drop('tip', axis=1)\n",
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b564152",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We will leave the `'total_bill'` column untouched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ab25c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To the `'size'` column, we will apply the `Binarizer` transformer with a threshold of 2 (big tables vs. small tables)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39414c70",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To the categorical columns, we will apply the `OneHotEncoder` transformer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05895b8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In essence, we will create a transformer that reproduces the following DataFrame:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>size</th>\n",
    "      <th>x0_Female</th>\n",
    "      <th>x0_Male</th>\n",
    "      <th>x1_No</th>\n",
    "      <th>x1_Yes</th>\n",
    "      <th>x2_Fri</th>\n",
    "      <th>x2_Sat</th>\n",
    "      <th>x2_Sun</th>\n",
    "      <th>x2_Thur</th>\n",
    "      <th>x3_Dinner</th>\n",
    "      <th>x3_Lunch</th>\n",
    "      <th>total_bill</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>16.99</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>1</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>10.34</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>1</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>21.01</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>23.68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>1</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>1.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>24.59</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89393533",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building a `Pipeline` using a `ColumnTransformer`\n",
    "\n",
    "Let's start by creating our `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7e5854",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('size', Binarizer(threshold=2), ['size']),\n",
    "        ('categorical_cols', OneHotEncoder(), ['sex', 'smoker', 'day', 'time'])\n",
    "    ],\n",
    "    remainder='passthrough' # Specify what to do with all other columns ('total_bill' here) ‚Äì drop or passthrough.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f5569",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, let's create a `Pipeline` using `preproc` as a transformer, and `fit` it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('preprocessor', preproc), \n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips_features, tips['tip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5db465",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prediction is as easy as calling `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3f595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tips_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we fit the Pipeline using tips_features, not tips_features.head()!\n",
    "pl.predict(tips_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b1a71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: `FunctionTransformer`\n",
    "\n",
    "A transformer you'll often use as part of a `ColumnTransformer` is the `FunctionTransformer`, which enables you to use your own functions on entire columns. Think of it as the `sklearn` equivalent of `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dbb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FunctionTransformer(np.sqrt)\n",
    "f.transform([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762df65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary, next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f679d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- To transform a categorical nominal variable into a quantitative variable, use one hot encoding.\n",
    "- To transform a categorical ordinal variable into a quantitative variable, use an ordinal encoding.\n",
    "- Quantitative feature transformations allow us to use linear models to model non-linear data.\n",
    "- `Pipeline`s are powerful because they allow you to perform feature engineering and training/prediction all through a single object.\n",
    "- As we'll see next time, they also allow us to easily compare models against each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24f95a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- More examples of, and ways to create, `Pipeline`s.\n",
    "- Multicollinearity.\n",
    "- Generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "livereveal": {
   "scroll": true
  },
  "rise": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
