
# Do NOT edit this file. Instead, just call it from the command line,
# using the instructions in the assignment notebook.

import sys
questions = sys.argv[1:]


valid_ids = ['q1', 'q2', 'q3', 'q4', 'q5', 'q6']
break_flag = False
invalid_ids = []
for question in questions:
    if question != 'all' and question not in valid_ids:
        invalid_ids.append(question)

if len(invalid_ids) > 0:
    print(str(invalid_ids) + ' is/are not a valid question number(s). The possible question numbers are ' + str(valid_ids) + '.')
    sys.exit()

# Initialize Otter
import otter
grader = otter.Notebook("lab.ipynb")

# %load_ext autoreload
# %autoreload 2

from lab import *

import pandas as pd
import numpy as np
from pathlib import Path
import plotly.express as px

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import FunctionTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

from pipeline_testing_util import get_transformers

from plotly.subplots import make_subplots
import plotly.graph_objects as go
import plotly.io as pio

import warnings
warnings.simplefilter('ignore')

# DSC 80 preferred styles
pio.templates["dsc80"] = go.layout.Template(
    layout=dict(
        margin=dict(l=30, r=30, t=30, b=30),
        autosize=True,
        width=800,
        height=500,
        xaxis=dict(showgrid=True),
        yaxis=dict(showgrid=True),
        title=dict(x=0.5, xanchor="center"),
    )
)
pio.templates.default = "simple_white+dsc80"

fp = Path('data') / 'toy.csv'
data = pd.read_csv(fp)
data.head()

# don't change this cell, but do run it -- it is needed for the tests to work
q1_fp = Path('data') / 'toy.csv'
q1_data = pd.read_csv(q1_fp)
q1_pl, q1_preds = simple_pipeline(q1_data)

if 'q1' in questions or questions == [] or 'all' in questions:
    print(grader.check("q1"))

# don't change this cell, but do run it -- it is needed for the tests to work
q2_fp = Path('data') / 'toy.csv'
q2_data = pd.read_csv(q2_fp)
q2_pl, q2_preds = multi_type_pipeline(q2_data)

if 'q2' in questions or questions == [] or 'all' in questions:
    print(grader.check("q2"))

# The scatter plot referenced at the start of Question 3
# This is not needed to answer the question, but motivates why we are standardizing
px.scatter(data, x='c1', y='y', color='group')

# don't change this cell, but do run it -- it is needed for the tests to work
# test fit 
q3_test_fit_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}
q3_test_fit_X = pd.DataFrame(q3_test_fit_cols)
q3_test_fit_std = StdScalerByGroup().fit(q3_test_fit_X)

# test transform
q3_test_transform_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}
q3_test_transform_X = pd.DataFrame(q3_test_transform_cols)
q3_test_transform_std = StdScalerByGroup().fit(q3_test_transform_X)
q3_test_transform_out = q3_test_transform_std.transform(q3_test_transform_X)

# don't change this cell, but do run it -- it is needed for the tests to work
q3_fit_data = pd.read_csv(Path('data') / 'toy.csv')

N = 2*10**6
a = np.random.choice(['A', 'B'], size=(N,1)).astype('object')
b = np.random.multivariate_normal([1, 2], [[1, 0],[0, 100]], size=N)
arr = np.hstack([a, b])
q3_transform_data = pd.DataFrame(arr)
q3_transform_data[1] = q3_transform_data[1].astype(float)
q3_transform_data[2] = q3_transform_data[2].astype(float)

if 'q3' in questions or questions == [] or 'all' in questions:
    print(grader.check("q3"))

if 'q4' in questions or questions == [] or 'all' in questions:
    print(grader.check("q4"))

# Use `galton` to test your work.
galton = pd.read_csv(Path('data') / 'galton.csv')
galton.head()

# don't change this cell, but do run it -- it is needed for the tests
galton_test = pd.read_csv(Path('data') / 'galton.csv')
out_tree_test = tree_reg_perf(galton_test)
out_knn_test = knn_reg_perf(galton_test)

if 'q5' in questions or questions == [] or 'all' in questions:
    print(grader.check("q5"))

pio.renderers.default = 'browser'

np.random.seed(9) # For reproducibility

tree = tree_reg_perf(galton)
knn = knn_reg_perf(galton)
hyp = np.arange(1, 21)

fig = make_subplots(rows=1, cols=2, subplot_titles=('Error vs. Tree Depth for Decision Tree Regressor',
                                                    'Error vs. k (# Neighbors) for k-NN Regressor'))

fig.add_trace(
    go.Scatter(x=hyp, y=tree.iloc[:, 0], name='Training Error'),
    row=1, col=1).add_trace(go.Scatter(x=hyp, y=tree.iloc[:, 1], name='Test Error'), 
                            row=1, col=1)

fig.add_trace(
    go.Scatter(x=hyp, y=knn.iloc[:, 0], line=dict(color='#1f77b4'), name='Training Error', showlegend=False),
    row=1, col=2).add_trace(go.Scatter(x=hyp, y=knn.iloc[:, 1], line=dict(color='#ff7f0f'),  name='Test Error',
                                       showlegend=False), row=1, col=2)

fig.update_layout(height=600, width=975)
fig.update_xaxes(title_text='Tree Depth', row=1, col=1, tickvals=np.arange(1,21,2))
fig.update_xaxes(title_text='k (# Neighbors)', row=1, col=2, tickvals=np.arange(1,21,2))

fig.show()

# Experiment using `titanic` below â€“ remember, this is only your training data
titanic = pd.read_csv(Path('data') / 'titanic.csv')
titanic.head()

# don't change this cell, but do run it -- it is needed for the tests
q6_data_test = pd.read_csv(Path('data') / 'titanic.csv')
pl_test = titanic_model(q6_data_test)

if 'q6' in questions or questions == [] or 'all' in questions:
    print(grader.check("q6"))


