{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eba1c2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777121e5",
   "metadata": {},
   "source": [
    "# Lab 9 ‚Äì Models and Pipelines üîÅ\n",
    "\n",
    "## DSC 80, Spring 2024\n",
    "\n",
    "### Due Date: Wednesday, June 5th at 11:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607ded9",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to the ninth and final DSC 80 lab this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2024-sp).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.** More details on its usage are given at the bottom of this notebook.\n",
    "\n",
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc1e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from pipeline_testing_util import get_transformers\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# DSC 80 preferred styles\n",
    "pio.templates[\"dsc80\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        width=800,\n",
    "        height=500,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+dsc80\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce00ef8",
   "metadata": {},
   "source": [
    "## Part 1: `sklearn` Pipelines üß†\n",
    "\n",
    "The file `data/toy.csv` contains an example dataset that consists of 4 columns:\n",
    "\n",
    "- `'group'`: a categorical column with 3 categories\n",
    "- `'c1'`: a numeric attribute\n",
    "- `'c2'`: a numeric attribute\n",
    "- `'y'`: the target variable (that you want to predict) \n",
    "```\n",
    "\n",
    "In the following questions, you will build `Pipeline`s that combine feature engineering with a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cbd33a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fp = Path('data') / 'toy.csv'\n",
    "data = pd.read_csv(fp)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb56f7f4",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "First, you will train a regression model using only a *log-scaled* `'c2'` variable. Create a `Pipeline` that:\n",
    "1. log-scales `'c2'`, then\n",
    "2. predicts `'y'` using a linear regression model (using your transformed `'c2'`).\n",
    "\n",
    "That is, complete the implementation of the function `simple_pipeline`, which takes in a DataFrame like `data` and returns a **tuple** consisting of \n",
    "- An already-fit `Pipeline`, and\n",
    "- An array containing the predictions your model makes on `data` (after being trained on `data`).\n",
    "\n",
    "***Note***: By \"log\", we're referring to the natural logarithm. In order to log-scale `'c2'`, you'll need to use a `FunctionTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f5716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629af745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q1_fp = Path('data') / 'toy.csv'\n",
    "q1_data = pd.read_csv(q1_fp)\n",
    "q1_pl, q1_preds = simple_pipeline(q1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a2258",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201350d",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Now, you will engineer features from the other columns and use them to train a regression model.  Create a `Pipeline` that:\n",
    "1. uses `'c1'` as is,\n",
    "1. log-scales `'c2'`,\n",
    "1. one-hot encodes `'group'`, and\n",
    "1. predicts `'y'` using a linear regression model built on the three variables above. (Note that your model will have more than three \"features\", because one-hot encoding `'group'` will create multiple columns. Don't drop any of them.)\n",
    "\n",
    "That is, complete the implementation of the function `multi_type_pipeline`, which takes in a DataFrame like `data` and returns a **tuple** consisting of\n",
    "- An already-fit `Pipeline`, and\n",
    "- An array containing the predictions your model makes on `data` (after being trained on `data`).\n",
    "\n",
    "***Hint***: Use `ColumnTransformer`, as we did in [Lecture 14](https://dsc80.com/resources/lectures/lec14/lec14.html#Planning-our-first-ColumnTransformer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71685d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9d676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28176a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q2_fp = Path('data') / 'toy.csv'\n",
    "q2_data = pd.read_csv(q2_fp)\n",
    "q2_pl, q2_preds = multi_type_pipeline(q2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d74c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb6ae6",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "It seems like `'c1'` and `'c2'` have strong associations with the values of `'group'` (to see this, run the cell below). This suggests that group-wise scaling might make good features. \n",
    "\n",
    "\n",
    "Now, we want to standardize (i.e. z-score) both `'c1'` and `'c2'` **within each `'group'`** (`'A'`, `'B'`, and `'C'`). Unfortunately, there is no built-in transformer in `sklearn` that performs group-wise standardization, so **you will need to create your own transformer!**\n",
    "\n",
    "Your job is to complete the implementation of the `StdScalerByGroup` transformer class, meaning that you need to implement the `fit` and `transform` methods, along with the constructor (`__init__`).\n",
    "- The `StdScalerByGroup` transformer works on an input array/DataFrame `X` whose first column contains groups, and whose remaining columns are quantitative and need to be standardized (within each group).\n",
    "- The `fit` method should determine the mean and standard deviation of each quantitative column within each group in the input data `X` and save them in the instance variable `grps_`. (For instance, one of the quantities you may calculate here is the standard deviation of `'c1'`, but only for the rows whose `'group'` is `'B'`.)\n",
    "- The `transform` method should take in an input array/DataFrame `X`, standardize each quantitative column separately using the means and standard deviations stored in `grps_`, and return a DataFrame containing the transformed quantitative columns.\n",
    "\n",
    "\n",
    "If you `fit` and `transform` a `StdScalerByGroup` transformer on the `toy` DataFrame (without the `'y'` column), you should get back a DataFrame with two columns, `'c1'` and `'c2'`, with groups stored in the index (if you end up creating a `MultiIndex`, that is fine).\n",
    "\n",
    "\n",
    "***Notes:***\n",
    "1. You may decide on whatever structure you'd like for the `grps_` variable. This question will be graded on the correctness of the output of your transformer. (Check the correctness of your work by checking the output by-hand!)    \n",
    "2. At no point should you loop over the **rows** of `data` (in fact, our solution doesn't use any loops), but you are allowed to use loop in this question.\n",
    "3. The `'group'` column in the public tests is named `'g'` instead of `'group'`. Remember, the first column will **always** contain the groups, even if the first column's name is something other than `'group'`.\n",
    "4. Don't worry about cases where the standard deviation is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scatter plot referenced at the start of Question 3\n",
    "# This is not needed to answer the question, but motivates why we are standardizing\n",
    "px.scatter(data, x='c1', y='y', color='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1f70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f8146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "# test fit \n",
    "q3_test_fit_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "q3_test_fit_X = pd.DataFrame(q3_test_fit_cols)\n",
    "q3_test_fit_std = StdScalerByGroup().fit(q3_test_fit_X)\n",
    "\n",
    "# test transform\n",
    "q3_test_transform_cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "q3_test_transform_X = pd.DataFrame(q3_test_transform_cols)\n",
    "q3_test_transform_std = StdScalerByGroup().fit(q3_test_transform_X)\n",
    "q3_test_transform_out = q3_test_transform_std.transform(q3_test_transform_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f752f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests to work\n",
    "q3_fit_data = pd.read_csv(Path('data') / 'toy.csv')\n",
    "\n",
    "N = 2*10**6\n",
    "a = np.random.choice(['A', 'B'], size=(N,1)).astype('object')\n",
    "b = np.random.multivariate_normal([1, 2], [[1, 0],[0, 100]], size=N)\n",
    "arr = np.hstack([a, b])\n",
    "q3_transform_data = pd.DataFrame(arr)\n",
    "q3_transform_data[1] = q3_transform_data[1].astype(float)\n",
    "q3_transform_data[2] = q3_transform_data[2].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09748c53",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c532d",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "`Pipeline`s are supposed to help you easily try different model configurations. Complete the implementation of the function `eval_toy_model`, which returns a hard-coded **list of tuples** consisting of the (RMSE, $R^2$) of three different modeling `Pipeline`s, fit and evaluated on the entire input dataset `data`. The three different `Pipeline`s are:\n",
    "1. The `Pipeline` in Question 1.\n",
    "1. The `Pipeline` in Question 2.\n",
    "1. A `Pipeline` consisting of a linear regression model fit on features generated by applying `StdScalerByGroup` to `'c1'`, log-scaling `'c2'`, and applying `OneHotEncoder` to `'group'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496af6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2d965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f9745",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507fd090",
   "metadata": {},
   "source": [
    "## Part 2: Overfitting üòü"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e0753a",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "In this question, you will train two different classes of prediction models ‚Äì **decision tree and k-Nearest Neighbor regressors** ‚Äì and explore different ways in which overfitting can appear. You'll use Galton's child heights dataset from the missingness lectures and Lab 5.\n",
    "\n",
    "#### `tree_reg_perf` üå≤\n",
    "\n",
    "A decision tree regressor is trained similar to a decision tree classifier: the splits of the tree are created by minimizing the variance of the (training data) response values in the leaves given by making the split in question. A decision tree regressor predicts the response value of a (new) observation based on the **average target value** of the training observations lying in the same leaf node. \n",
    "\n",
    "One **hyperparameter** of a decision tree regressor that affects model complexity is the **depth** of the tree. Larger depths correspond to more complicated decision trees. We will explore this parameter in this question.\n",
    "\n",
    "Complete the implementation of the function `tree_reg_perf`, which takes in a DataFrame like `galton` and:\n",
    "- Splits the data into training and test sets,\n",
    "- Trains 20 decision trees ‚Äì one for each depth between 1 and 20, and\n",
    "- Computes both the training RMSE and test RMSE of each tree.\n",
    "\n",
    "Store and return your results in a DataFrame that has two columns, `'train_err'` and `'test_err'`, and an index that corresponds to tree depths (i.e. 1, 2, ..., 20).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `knn_reg_perf` üëâüëà\n",
    "\n",
    "A k-Nearest Neighbors (k-NN) regressor predicts the response value of a (new) observation by computing the average value of the k-closest observations in the training set. The most common distance metric is Euclidean distance, i.e. $L_2$ distance.\n",
    "\n",
    "One **hyperparameter** of a k-NN regressor that affects model complexity is k, **the number of neighbors averaged over**. Larger values of k correspond to more complicated regressors. We will explore this hyperparameter in this question.\n",
    "\n",
    "Complete the implementation of the function `knn_reg_perf`, which takes in a DataFrame like `galton` and:\n",
    "- Splits the data into training and test sets,\n",
    "- Trains 20 k-NN regressors ‚Äì one for each value of k between 1 and 20, and\n",
    "- Computes both the training RMSE and test RMSE of each regressor.\n",
    "\n",
    "Again, store and return your results in a DataFrame that has two columns, `'train_err'` and `'test_err'`, and an index that corresponds to values of k (i.e. 1, 2, ..., 20).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Some guidelines for both subparts:**\n",
    "\n",
    "- In all cases, we are using all other columns in `galton` to predict `'childHeight'`.\n",
    "- You need to import the necessary classes from `sklearn` **inside** the functions you create. (Unlike before, we haven't imported them for you because we want you to figure out what to import!)\n",
    "- If you're unsure how to create training and testing sets, refer to [Lecture 15](https://dsc80.com/resources/lectures/lec15/lec15.html#Train-test-splits). Use a test set size of 0.25. Within each function, you should only perform a single train-test split ‚Äì that is, you should not be creating training and testing sets within a `for`-loop (though you will need to use a `for`-loop for something else).\n",
    "    - For the purposes of this question, do not use any cross-validation.\n",
    "- Don't write the formula for RMSE four times ‚Äì define a helper function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69132b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `galton` to test your work.\n",
    "galton = pd.read_csv(Path('data') / 'galton.csv')\n",
    "galton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688608d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39639b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfe364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "galton_test = pd.read_csv(Path('data') / 'galton.csv')\n",
    "out_tree_test = tree_reg_perf(galton_test)\n",
    "out_knn_test = knn_reg_perf(galton_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088991b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2f93d",
   "metadata": {},
   "source": [
    "After you've implemented both functions, run the cells below to plot training and testing error for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = 'browser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be922e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9) # For reproducibility\n",
    "\n",
    "tree = tree_reg_perf(galton)\n",
    "knn = knn_reg_perf(galton)\n",
    "hyp = np.arange(1, 21)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Error vs. Tree Depth for Decision Tree Regressor',\n",
    "                                                    'Error vs. k (# Neighbors) for k-NN Regressor'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=hyp, y=tree.iloc[:, 0], name='Training Error'),\n",
    "    row=1, col=1).add_trace(go.Scatter(x=hyp, y=tree.iloc[:, 1], name='Test Error'), \n",
    "                            row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=hyp, y=knn.iloc[:, 0], line=dict(color='#1f77b4'), name='Training Error', showlegend=False),\n",
    "    row=1, col=2).add_trace(go.Scatter(x=hyp, y=knn.iloc[:, 1], line=dict(color='#ff7f0f'),  name='Test Error',\n",
    "                                       showlegend=False), row=1, col=2)\n",
    "\n",
    "fig.update_layout(height=600, width=975)\n",
    "fig.update_xaxes(title_text='Tree Depth', row=1, col=1, tickvals=np.arange(1,21,2))\n",
    "fig.update_xaxes(title_text='k (# Neighbors)', row=1, col=2, tickvals=np.arange(1,21,2))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aae650",
   "metadata": {},
   "source": [
    "If your training and evaluation routines are correct, you should notice a few things:\n",
    "- In both models, test error initially decreases, and then (perhaps slowly) increases.\n",
    "- With the decision tree, training error **decreases** as depth increases.\n",
    "- With the k-NN regressor, training error **increases** as k (the number of neighbors looked at) increases.\n",
    "\n",
    "You should think about **why** you observe each of the above phenomena. In particular, the last point may seem confusing ‚Äì one would think that because larger values of k correspond to more complicated models (because the regressor is looking at more information to make a prediction), larger values of k should have lower training errors. But the nature of k-NN regressors is quite different than, say, decision tree regressors or linear regression models.\n",
    "\n",
    "Lastly, in both cases, identify the ideal **hyperparameter** choice based on the graphs of test error. You don't have to write the answer anywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9eb85b",
   "metadata": {},
   "source": [
    "## Part 3: Predicting Survival on the Titanic üõ≥üßä"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d218efa",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Predicting whether or not passengers on the Titanic survived is a common first assignment when learning about classification ‚Äì now it's your turn!\n",
    "\n",
    "Complete the implementation of the function `titanic_model`, which takes in a DataFrame `titanic` containing **training data only** and returns a `Pipeline` object fit to the training data. \n",
    "\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "You have freedom to build your own model. That is, **you can use any classification algorithm**, but your model should satisfy the following requirements:\n",
    "\n",
    "- The model is built on the (binary) response column `'Survived'`.\n",
    "* The model uses features derived from **all other columns in `titanic`**. Below, we specify which columns to \"engineer\"; you may \"engineer\" features using other columns, but be sure to include every column in your model (even if you choose to leave some columns as-is).\n",
    "\n",
    "* Required feature engineering:\n",
    "    * Derive a feature from the \"title\" in the `'Name'` field (e.g. \"Mr\", \"Miss\", \"Mrs\" ‚Äì the names themselves should not be used as a feature; think about why).\n",
    "    * Derive a feature that standardizes passengers' ages among their `'Pclass'` (use Question 3!).\n",
    "    \n",
    "#### Evaluation\n",
    "    \n",
    "Your model must achieve an accuracy of 0.78 on both the training set and the test set. Note that while you have access to the test set, it is still encouraged to perform your own model validation.\n",
    "\n",
    "**Extra credit: If your model can consistently earn an accuracy of above 0.83 on the test set, you can earn 5 points of extra credit on the lab!** That is, you can earn up to 60 points on the lab, even though it is only graded out of 55 points (meaning you _can_ have a score above 100% on the lab).\n",
    "\n",
    "Some guidance:\n",
    "\n",
    "- `Pipeline` objects can have other `Pipeline` objects within them. While this isn't a requirement, you may find this useful to break down your model into smaller, more manageable steps.\n",
    "    - You can even create a `Pipeline` made up of transformers only, if you want to perform multiple transformations on a single column. We did this in [Lecture 15](https://dsc80.com/resources/lectures/lec15/lec15.html#Standardization).\n",
    "    - The function `make_pipeline` from [Lecture 15](https://dsc80.com/resources/lectures/lec15/lec15.html#%F0%9F%92%A1-Pro-Tip:-Using-make_pipeline).\n",
    "- Your submitted `titanic_model` function should have the model's hyperparameters (e.g. tree depth) hard-coded in it. That is, the `Pipeline` object doesn't have to include the hyperparameter selection process.\n",
    "- You will find the [`FunctionTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) class useful. If you want your transformer to output a categorical feature, you may need to specify `validate=False`.\n",
    "- When using the [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer) class , you may find the `remainder` keyword helpful.\n",
    "- If you are set out to get those extra 5 points, consider building some meaningful features before fine-tuning the hyperparameters of your model. Do an EDA on the dataset ‚Äì what kinds of people are more prone to survive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment using `titanic` below ‚Äì remember, this is only your training data\n",
    "titanic = pd.read_csv(Path('data') / 'titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c8a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523bfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell, but do run it -- it is needed for the tests\n",
    "q6_data_test = pd.read_csv(Path('data') / 'titanic.csv')\n",
    "pl_test = titanic_model(q6_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f0144",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e0c2f",
   "metadata": {},
   "source": [
    "There is **a ton** of material out there on analyzing data from the Titanic. After you build your model, look online for other examples (e.g. [on Kaggle](https://www.kaggle.com/c/titanic)) and think about how you could improve your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4348fb67",
   "metadata": {},
   "source": [
    "## Congratulations! You're done Lab 9! üèÅ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.\n",
    "\n",
    "Once you've finished the lab, you should open the command line and run, in the directory for this lab:\n",
    "\n",
    "```\n",
    "python lab-validation.py\n",
    "```\n",
    "\n",
    "**This will run all of the `grader.check` cells that you see in this notebook, but only using the code in `lab.py` ‚Äì that is, it doesn't look at any of the code in this notebook. If all of your `grader.check` cells pass in this notebook but not all of them pass in your command line with the above command, then you likely have code in your notebook that isn't in your `lab.py`!**\n",
    "\n",
    "You can also use `lab-validation.py` to test individual questions. For instance,\n",
    "\n",
    "```\n",
    "python lab-validation.py q1 q2 q4\n",
    "```\n",
    "\n",
    "will run the `grader.check` cells for Questions 1, 2, and 4 ‚Äì again, only using the code in `lab.py`. [This video](https://www.loom.com/share/0ea254b85b2745e59322b5e5a8692e91?sid=5acc92e6-0dfe-4555-9b6a-8115b6a52f99) how to use the script as well.\n",
    "\n",
    "Once `python lab-validation.py` shows that you're passing all test cases, you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31b3f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d48f3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q1_pl, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q1_pl.steps[-1][1], LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q1_pl.steps[0][1], FunctionTransformer)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q1_preds.shape[0] == q1_data.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(q2_pl, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q2_pl.steps[-1][1], LinearRegression)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(q2_pl.steps[0][1], ColumnTransformer)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q2_data.shape[0] == q2_preds.shape[0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> q3_test_fit_std.grps_ is not None\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> q3_test_transform_out.shape == (4, 2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> np.isclose(q3_test_transform_out.abs(), 0.707107, atol=0.001).all().all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out = eval_toy_model()\n>>> len(out) == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> out = eval_toy_model()\n>>> np.all([len(t) == 2 for t in out])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> (out_tree_test.columns.tolist() == ['train_err', 'test_err']) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_tree_test['train_err'].iloc[-1] < out_tree_test['test_err'].iloc[-1]) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_knn_test.columns.tolist() == ['train_err', 'test_err']) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(pl_test, Pipeline)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(pl_test.steps[-1][-1], BaseEstimator)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> preds_test = pl_test.predict(q6_data_test.drop('Survived', axis=1))\n>>> ((preds_test == 0) | (preds_test == 1)).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
